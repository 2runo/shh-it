
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: ./nb/main.ipynb

import sys
from pprint import pprint
import requests
import socket
import urllib
from xml.dom.minidom import parseString
import html
import copy
from functools import partial
import json
import re

if __name__ == '__main__':
    sys.path.append('..')


socket.setdefaulttimeout(5.)


# dealing with xml.dom
def getVal(dom, key):
    att = dom.attributes[key]
    return att.value


def eachTxt(txt, remove_font_tag):
    start = getVal(txt, 'start')
    dur = getVal(txt, 'dur')
    if txt.firstChild is None:
        # fix dl-youtube-cc.exe Zd14s2WW-Tc --caption_num=1
        txt = ""
    else :
        txt = html.unescape((txt.firstChild.data))
        if remove_font_tag:
            txt =   re.sub(r'</?font[^>]*>','', txt)
    return {
        "start":start,
        "dur": dur,
        "text": txt
    }


def get_data(link):
    data = requests.get(link)
    data = data.text
    return data


def get_tracks_title(data):
    decodedData = urllib.parse.unquote(data)
    if 'captionTracks' not in decodedData:
        return None
    match = re.search(r'({"captionTracks":.*isTranslatable":(true|false)}])', decodedData)
    match = match.group(1)
    match = f"{match}}}"
    captionTracks =  json.loads(match)['captionTracks']
    match = re.search(r'title":"(.*?)","lengthSeconds":', decodedData)
    title = match.group(1)
    return captionTracks, title


def parseTranscript(transcript, remove_font_tag=True):
    try:
        dom = parseString(transcript.text)
    except :
        return None
    texts = dom.getElementsByTagName('text')

    _eachTxt = partial(eachTxt, remove_font_tag=remove_font_tag)
    texts = list(map( _eachTxt, texts,))
    return texts


def get_valid_filename(s):
    s = str(s).strip().replace(' ', '_')
    return re.sub(r'(?u)[^-\w.]', '', s)


def merge_subtitle(subtitle, subtitle_cn):
    subtitle = copy.deepcopy(subtitle) # original transcript
    subtitle_cn = copy.deepcopy(subtitle_cn) # translation script

    TRANSLATE_TEXT = "translate_text"
    TEXT = "text"
    START = "start"

    # NOTE not sure how to merge them properly

    # indexer for subtitle
    sub_p = 0
    sub_p_cn = 0

    while sub_p < len(subtitle) and sub_p_cn < len(subtitle_cn):

        sub = subtitle[sub_p]
        sub_cn = subtitle_cn[sub_p_cn]

        if TRANSLATE_TEXT not in sub: sub[TRANSLATE_TEXT] = ""

        if float(sub[START]) >= float(sub_cn[START]) :
        # sub goes first, being chased by sub_cn

            # for separating the sentence
            if len(sub[TRANSLATE_TEXT]) != 0: sub[TRANSLATE_TEXT] += "\n"

            sub[TRANSLATE_TEXT] +=  sub_cn[TEXT]

            sub_p_cn += 1

        else :
            sub_p += 1

    # add empty field for subitle
    while sub_p < len(subtitle):
        assert sub_p_cn == len(subtitle_cn)

        sub = subtitle[sub_p]
        if TRANSLATE_TEXT not in sub: sub[TRANSLATE_TEXT] = ""
        sub_p += 1

    # add the rest of subtitle_cn to the last one of subtitle
    while sub_p_cn < len(subtitle_cn):
        assert sub_p == len(subtitle)

        sub = subtitle[-1]

        if TRANSLATE_TEXT not in sub: sub[TRANSLATE_TEXT] = ""

        if len(sub[TRANSLATE_TEXT]) != 0: sub[TRANSLATE_TEXT] += "\n"

        sub[TRANSLATE_TEXT] += sub_cn[TEXT]
        sub_p_cn += 1

    assert sub_p == len(subtitle)
    assert sub_p_cn == len(subtitle_cn)

    return subtitle


def format_caption(caption):
    ret = f"{caption['vssId']:8s} {caption['name']['simpleText']}"
    if 'a.' in caption['vssId']:
        ret += ' automatically generated by youtube'
    return ret


def parseVideoID(videoID):
    if 'youtu' in videoID:
        videoID = re.search('v=([^&]+)', videoID).group(1)

    video_link = f'https://www.youtube.com/watch?v={videoID}'
    data_link=f"https://youtube.com/get_video_info?video_id={videoID}"
    return videoID, video_link, data_link


def main(video_id, remove_font_tag=True):
    video_id, video_link, data_link = parseVideoID(video_id)
    data = get_data(data_link)
    out = get_tracks_title(data)
    if not out:
        # 없는 동영상이라면?
        return None
    caption_tracks, title = out

    caption_tracks = [i for i in caption_tracks if i['languageCode'] == 'ko']

    if not caption_tracks:
        # 자막이 없으면
        return None

    caption = caption_tracks[0]

    transcript = requests.get(caption['baseUrl'])

    _parseTranscript = partial(parseTranscript, remove_font_tag=remove_font_tag)

    subtitle = _parseTranscript(transcript, )
    sent_subtitle = subtitle

    return sent_subtitle
